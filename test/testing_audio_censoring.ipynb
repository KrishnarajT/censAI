{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is case 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we tried diarizing and stuff but it seems too overly complicated. the idea was to maybe make the speaker say something else instead of the profane word they used by an ai model trained on theri voice, if we could diarize it, we could identify what that speaker is, then figure out their dialoges from subtitles by matching with the diarizing output, then cut that part of audio out from the episode, and simlilarly make out a collection of data for that audio, and then train our model on it and instead of saying \"fuck\" you could have the model generate a different word like \"freak\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that could work but it seems far too much work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we used whisper for this. so in case we do not have subtitles, then yes, we could use whisper to generate a transcript and then remove profanity. it should work for the entire project anyway coz you can generate srt files from whisper and then thats the same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we also tried using whisper x to diarize but it didnt really work out and time spent to install and fix the whole thing would be too much effort for very less returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now let us try instead to just remove the audio for the profane word, which should be simple enough to do, for many shows, including say severance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the subtitle well get start and end time of a dialogue. lets mute it using ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# say start time is 00:00:00, end time is 00:00:05\n",
    "import pysrt\n",
    "\n",
    "# subs = pysrt.open('ep1.srt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pysrt.open(\"ep1.srt\")\n",
    "mute_sections = \"\"\n",
    "for sub in subs:\n",
    "    start = sub.start.to_time()\n",
    "    end = sub.end.to_time()\n",
    "    mute_sections += f\"volume=enable='between(t,{start.hour*3600+start.minute*60+start.second},{end.hour*3600+end.minute*60+end.second})':volume=0,\"\n",
    "# Remove last comma\n",
    "mute_sections = mute_sections.rstrip(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m \u001b[43msubs\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstart\u001b[38;5;241m.\u001b[39mto_time()\n\u001b[0;32m      2\u001b[0m end_time \u001b[38;5;241m=\u001b[39m subs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mend\u001b[38;5;241m.\u001b[39mto_time()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'subs' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = subs[0].start.to_time()\n",
    "end_time = subs[0].end.to_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in p:\\programs\\dsml\\dsmlenv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: future in p:\\programs\\dsml\\dsmlenv\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets mute that audio in the video using ffmpeg\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video = \"ep1.mkv\"\n",
    "output_video = \"ep1_muted.mkv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire video directly. its larger smh\n",
    "ffmpeg.input(input_video).output(output_video, af=mute_sections).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffmpeg.input(\"ep1.aac\").output(\"ep1_muted.aac\", af=mute_sections, acodec=\"aac\").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = ffmpeg.input(input_video)\n",
    "audio = ffmpeg.input(\"ep1_muted.aac\")\n",
    "\n",
    "ffmpeg.output(\n",
    "    video, audio, \"ep1_audio_muted_remux.mkv\", vcodec=\"copy\", acodec=\"aac\"\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import pysrt\n",
    "\n",
    "# Input and output files\n",
    "input_video = \"ep1.mkv\"\n",
    "extracted_audio = \"ep1_audio_method2.mka\"  # Extracted audio format remains unchanged\n",
    "muted_audio = \"muted_audio_method2.mka\"\n",
    "output_video = \"ep1_muted_method2.mkv\"\n",
    "\n",
    "# Step 1: Extract the original audio (without re-encoding)\n",
    "ffmpeg.input(input_video).output(extracted_audio, vn=None, acodec=\"copy\").run()\n",
    "\n",
    "# Step 2: Parse subtitles and generate mute filter\n",
    "subs = pysrt.open(\"ep1.srt\")\n",
    "mute_sections = [\n",
    "    f\"volume=enable='between(t,{sub.start.ordinal / 1000},{sub.end.ordinal / 1000})':volume=0\"\n",
    "    for sub in subs\n",
    "]\n",
    "mute_filter = \",\".join(mute_sections)\n",
    "\n",
    "# Step 3: Apply mute filter to extracted audio\n",
    "ffmpeg.input(extracted_audio).output(muted_audio, af=mute_filter, acodec=\"copy\").run()\n",
    "\n",
    "# Step 4: Remux muted audio with original video (no re-encoding)\n",
    "video = ffmpeg.input(input_video)\n",
    "audio = ffmpeg.input(muted_audio)\n",
    "ffmpeg.output(video, audio, output_video, vcodec=\"copy\", acodec=\"copy\").run()\n",
    "\n",
    "print(\"Processing complete. Check\", output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
